{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[980, 1135, 1924, 1010, 982, 0, 958, 1028, 974, 1009]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from model import LeNet5\n",
    "from dataloader import MNISTDataLoader\n",
    "\n",
    "\n",
    "my_data = MNISTDataLoader()\n",
    "\n",
    "my_dist = [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]\n",
    "my_data.sample_bias(my_dist, dataset=\"train\", dist_is_freq=True)\n",
    "# my_data.plot_dist(dataset=\"train\")\n",
    "\n",
    "my_data.corrupt_targets(5, 2, freq_corrupt=1.0, dataset=\"test\")\n",
    "my_data.plot_dist(dataset=\"test\")\n",
    "my_data.get_curr_dist(dataset=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l_f_hat 2.3242411613464355\n",
      "l_f_hat 2.3217854499816895\n",
      "l_f_hat 2.315406322479248\n",
      "l_f_hat 2.332038640975952\n",
      "l_f_hat 2.327238082885742\n",
      "l_f_hat 2.3230910301208496\n",
      "l_f_hat 2.3088366985321045\n",
      "l_f_hat 2.3225326538085938\n",
      "l_f_hat 2.299659013748169\n",
      "l_f_hat 2.3053503036499023\n",
      "l_f_hat 2.3300840854644775\n",
      "l_f_hat 2.2957170009613037\n",
      "l_f_hat 2.3306405544281006\n",
      "l_f_hat 2.303028106689453\n",
      "l_f_hat 2.3026282787323\n",
      "l_f_hat 2.317584991455078\n",
      "l_f_hat 2.3102593421936035\n",
      "l_f_hat 2.321739435195923\n",
      "l_f_hat 2.3162500858306885\n",
      "l_f_hat 2.314568281173706\n",
      "l_f_hat 2.3102641105651855\n",
      "l_f_hat 2.3309311866760254\n",
      "l_f_hat 2.3120129108428955\n",
      "l_f_hat 2.3194522857666016\n",
      "l_f_hat 2.321934223175049\n",
      "l_f_hat 2.3292956352233887\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 245\u001b[0m\n\u001b[0;32m    241\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m data_loader\u001b[38;5;241m.\u001b[39mtest_dataloader\n\u001b[0;32m    243\u001b[0m \u001b[38;5;66;03m# NoReweighting(network, hyperparameters, criterion, optimizer, train_loader, test_loader).train()\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;66;03m# NaiveReweighting(network, hyperparameters, criterion, optimizer, train_loader, test_loader).train()\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m Reweighting(network, hyperparameters, criterion, criterion_mean, optimizer, train_loader, test_loader)\u001b[38;5;241m.\u001b[39mtrain()\n",
      "Cell \u001b[1;32mIn[10], line 148\u001b[0m, in \u001b[0;36mReweighting.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# get batch of data from train_loader\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m X_f, y_f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader))\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# print(\"X_f\", X_f.size())\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# TODO: get batch of data from validation_loader (it is currently fixed outside the loop)\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Line 4\u001b[39;00m\n\u001b[0;32m    154\u001b[0m y_f_hat \u001b[38;5;241m=\u001b[39m y_f_hat\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[1;32mc:\\Users\\jjuus\\anaconda3\\envs\\ECE50024\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\jjuus\\anaconda3\\envs\\ECE50024\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\jjuus\\anaconda3\\envs\\ECE50024\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\jjuus\\anaconda3\\envs\\ECE50024\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\jjuus\\anaconda3\\envs\\ECE50024\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(img)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\Users\\jjuus\\anaconda3\\envs\\ECE50024\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\jjuus\\anaconda3\\envs\\ECE50024\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jjuus\\anaconda3\\envs\\ECE50024\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jjuus\\anaconda3\\envs\\ECE50024\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mnormalize(tensor, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstd, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minplace)\n",
      "File \u001b[1;32mc:\\Users\\jjuus\\anaconda3\\envs\\ECE50024\\Lib\\site-packages\\torchvision\\transforms\\functional.py:349\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39mnormalize(tensor, mean\u001b[38;5;241m=\u001b[39mmean, std\u001b[38;5;241m=\u001b[39mstd, inplace\u001b[38;5;241m=\u001b[39minplace)\n",
      "File \u001b[1;32mc:\\Users\\jjuus\\anaconda3\\envs\\ECE50024\\Lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:920\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    918\u001b[0m mean \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(mean, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    919\u001b[0m std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(std, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (std \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd evaluated to zero after conversion to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, leading to division by zero.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mean\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "# from torchviz import make_dot\n",
    "\n",
    "from model import LeNet5\n",
    "from meta_model import MetaModule, LeNet\n",
    "from dataloader import MNISTDataLoader \n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(1)\n",
    "\n",
    "class NoReweighting():\n",
    "    def __init__(self, network, hyperparameters, criterion, optimizer, train_loader, test_loader):\n",
    "        self.network = network\n",
    "        self.hyperparameters = hyperparameters\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "\n",
    "    def train(self):\n",
    "        # Train the network\n",
    "        for epoch in range(hyperparameters['n_epochs']):\n",
    "            self.network.train()\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.network(data)\n",
    "                loss = self.criterion(output, target)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                if batch_idx % hyperparameters['log_interval'] == 0:\n",
    "                    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                        100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "        # Test the network\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for data, target in test_loader:\n",
    "            self.network.eval()\n",
    "            output = self.network(data)\n",
    "            test_loss += self.criterion(output, target).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "\n",
    "        print('\\nTest set: \\nAvg. loss: {:.4f} \\nAccuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(test_loader.dataset),\n",
    "            100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "class NaiveReweighting():\n",
    "    def __init__(self, network, hyperparameters, criterion, optimizer, train_loader, test_loader):\n",
    "        self.network = network\n",
    "        self.hyperparameters = hyperparameters\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "    # TODO:\n",
    "\n",
    "class NoReweighting():\n",
    "    def __init__(self, network, hyperparameters, criterion, optimizer, train_loader, test_loader):\n",
    "        self.network = network\n",
    "        self.hyperparameters = hyperparameters\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "\n",
    "    def train(self):\n",
    "        # Train the network\n",
    "        for epoch in range(hyperparameters['n_epochs']):\n",
    "            self.network.train()\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.network(data)\n",
    "                loss = self.criterion(output, target)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                if batch_idx % hyperparameters['log_interval'] == 0:\n",
    "                    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                        100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "        # Test the network\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for data, target in test_loader:\n",
    "            self.network.eval()\n",
    "            output = self.network(data)\n",
    "            test_loss += self.criterion(output, target).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "\n",
    "        print('\\nTest set: \\nAvg. loss: {:.4f} \\nAccuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(test_loader.dataset),\n",
    "            100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "class NaiveReweighting():\n",
    "    def __init__(self, network, hyperparameters, criterion, optimizer, train_loader, test_loader):\n",
    "        self.network = network\n",
    "        self.hyperparameters = hyperparameters\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "    # TODO:\n",
    "\n",
    "class Reweighting():\n",
    "    def __init__(self, network, hyperparameters, criterion, criterion_mean, optimizer, train_loader, test_loader):\n",
    "        self.network = network.requires_grad_(requires_grad=True)\n",
    "        self.hyperparameters = hyperparameters\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.criterion_mean = criterion_mean\n",
    "\n",
    "    def train(self):\n",
    "        # X_g = LeNet5()\n",
    "        # print(\"Starting training...\")\n",
    "        X_g, y_g = next(iter(self.train_loader))\n",
    "        # X_g = X_g.requires_grad_(requires_grad=True)\n",
    "        # Train the network\n",
    "        y_f_hat = torch.empty(1)\n",
    "\n",
    "        theta_tp1 = self.network.state_dict()\n",
    "        for i in range(self.hyperparameters['n_epochs']):\n",
    "            # print(\"Epoch loop\")\n",
    "            self.network = LeNet(n_out=10)\n",
    "            self.network.load_state_dict(theta_tp1)\n",
    "            \n",
    "            # for param in theta_tp1:\n",
    "            #     param.grad = None\n",
    "            # self.network.our_update_params(theta_tp1)\n",
    "\n",
    "            # self.network.detach_params()\n",
    "            # self.network.our_update_params(self.network.params())\n",
    "            # self.network.copy(self.network, same_var=False)\n",
    "\n",
    "            self.network.zero_grad()        #zero out any previously accumulated gradient before doing autograd\n",
    "\n",
    "            self.network.train()\n",
    "            # get batch of data from train_loader\n",
    "            X_f, y_f = next(iter(self.train_loader))\n",
    "            # print(\"X_f\", X_f.size())\n",
    "\n",
    "            # TODO: get batch of data from validation_loader (it is currently fixed outside the loop)\n",
    "\n",
    "            # Line 4\n",
    "            y_f_hat = y_f_hat.detach()\n",
    "            # make_dot(y_f_hat).render(\"y_f_hat\", format=\"png\")\n",
    "            y_f_hat = self.network(X_f)\n",
    "            \n",
    "\n",
    "            # Line 5\n",
    "            epsilon = torch.zeros(y_f.size(), requires_grad=True)\n",
    "            Costs = self.criterion(y_f_hat, y_f)\n",
    "            l_f = torch.sum(torch.mul(Costs, epsilon))\n",
    "            # l_f = torch.sum(Costs * epsilon)\n",
    "            # make_dot(l_f).render(\"l_f\", format=\"png\")\n",
    "            \n",
    "\n",
    "            # Line 6\n",
    "            grad_t = torch.autograd.grad(outputs=l_f, inputs=self.network.params(), create_graph=True)\n",
    "            # grad_t = torch.autograd.grad(l_f, self.network.parameters(), only_inputs=True)\n",
    "            # make_dot(grad_t).render(\"grad_t\", format=\"png\")\n",
    "            \n",
    "\n",
    "            # Line 7: manually update the weights of the validation network\n",
    "            theta_t = self.network.params()\n",
    "\n",
    "            lr = self.hyperparameters['learning_rate']\n",
    "            self.network.our_update_params_with_step(lr, grad_t)\n",
    "\n",
    "            # Line 8\n",
    "            # Model has theta_hat\n",
    "            y_g_hat = self.network(X_g)\n",
    "\n",
    "            # Line 9\n",
    "            l_g = self.criterion_mean(y_g_hat, y_g)\n",
    "            # make_dot(l_g).render(\"want_big_graph\", format=\"png\")\n",
    "            # print(y_g_hat)\n",
    "\n",
    "            # Line 10\n",
    "            grad_epsilon = torch.autograd.grad(l_g, epsilon, only_inputs=True)[0]\n",
    "            # make_dot(grad_epsilon).render(\"grad_epsilon\", format=\"png\")\n",
    "\n",
    "            # Line 11\n",
    "            w_tilde = torch.clamp(grad_epsilon, min=0)\n",
    "\n",
    "            if torch.sum(w_tilde) != 0:\n",
    "                w = w_tilde / torch.sum(w_tilde)\n",
    "            else:\n",
    "                w = w_tilde\n",
    "\n",
    "            # Line 12\n",
    "            l_f_hat = torch.sum(torch.mul(Costs, w))\n",
    "            print(\"l_f_hat\", l_f_hat.item())\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Line 13\n",
    "            \n",
    "            self.network.our_update_params(theta_t)\n",
    "            l_f_hat.backward()\n",
    "\n",
    "            # Line 14\n",
    "            self.optimizer.step()\n",
    "            # break\n",
    "\n",
    "            theta_tp1 = self.network.state_dict()\n",
    "\n",
    "            \n",
    "                \n",
    "network = LeNet(n_out=10)\n",
    "\n",
    "hyperparameters = {\n",
    "    'n_epochs' : 8000,\n",
    "    'batch_size_train' : 100,\n",
    "    'batch_size_test' : 1000,\n",
    "    'learning_rate' : 1e-3,\n",
    "    'momentum' : 0.5,\n",
    "    'log_interval' : 10\n",
    "}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "# criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
    "criterion_mean = nn.CrossEntropyLoss(reduction='mean')\n",
    "# criterion_mean = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "\n",
    "optimizer = optim.SGD(network.params(),\n",
    "                        lr=hyperparameters['learning_rate'],\n",
    "                        momentum=hyperparameters['momentum'])\n",
    "# Load the data\n",
    "data_loader = MNISTDataLoader(batch_size_train=hyperparameters['batch_size_train'],\n",
    "                                batch_size_test=hyperparameters['batch_size_test'])\n",
    "train_loader = data_loader.train_dataloader\n",
    "test_loader = data_loader.test_dataloader\n",
    "\n",
    "# NoReweighting(network, hyperparameters, criterion, optimizer, train_loader, test_loader).train()\n",
    "# NaiveReweighting(network, hyperparameters, criterion, optimizer, train_loader, test_loader).train()\n",
    "Reweighting(network, hyperparameters, criterion, criterion_mean, optimizer, train_loader, test_loader).train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd\n",
    "import torchvision\n",
    "from torchviz import make_dot\n",
    "import matplotlib.pyplot as plt\n",
    "# from torchviz import make_dot\n",
    "\n",
    "from model import LeNet5\n",
    "from meta_model import MetaModule, LeNet\n",
    "from dataloader import MNISTDataLoader \n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(1)\n",
    "\n",
    "class NoReweighting():\n",
    "    def __init__(self, network, hyperparameters, criterion, optimizer, train_loader, test_loader):\n",
    "        self.network = network\n",
    "        self.hyperparameters = hyperparameters\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "\n",
    "    def train(self):\n",
    "        # Train the network\n",
    "        for epoch in range(hyperparameters['n_epochs']):\n",
    "            self.network.train()\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.network(data)\n",
    "                loss = self.criterion(output, target)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                if batch_idx % hyperparameters['log_interval'] == 0:\n",
    "                    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                        100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "        # Test the network\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for data, target in test_loader:\n",
    "            self.network.eval()\n",
    "            output = self.network(data)\n",
    "            test_loss += self.criterion(output, target).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "\n",
    "        print('\\nTest set: \\nAvg. loss: {:.4f} \\nAccuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(test_loader.dataset),\n",
    "            100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "class NoReweighting():\n",
    "    def __init__(self, network, hyperparameters, criterion, optimizer, train_loader, test_loader):\n",
    "        self.network = network\n",
    "        self.hyperparameters = hyperparameters\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "\n",
    "    def train(self):\n",
    "        # Train the network\n",
    "        for epoch in range(hyperparameters['n_epochs']):\n",
    "            self.network.train()\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.network(data)\n",
    "                loss = self.criterion(output, target)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                if batch_idx % hyperparameters['log_interval'] == 0:\n",
    "                    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                        100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "        # Test the network\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for data, target in test_loader:\n",
    "            self.network.eval()\n",
    "            output = self.network(data)\n",
    "            test_loss += self.criterion(output, target).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "\n",
    "        print('\\nTest set: \\nAvg. loss: {:.4f} \\nAccuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(test_loader.dataset),\n",
    "            100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "class NaiveReweighting():\n",
    "    def __init__(self, network, hyperparameters, criterion, criterion_mean, optimizer, train_loader, valid_loader, test_loader):\n",
    "        self.network = network.requires_grad_(requires_grad=True)\n",
    "        self.hyperparameters = hyperparameters\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.valid_loader = valid_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.criterion_mean = criterion_mean\n",
    "\n",
    "    def train(self):\n",
    "        # Outside loop modifies weight tensor\n",
    "        weight_vec = torch.ones(len(train_loader.dataset)) * 1.0/len(train_loader.dataset)\n",
    "        weight_vec.requires_grad_()\n",
    "\n",
    "        # Sample validation dataset\n",
    "        X_g, y_g = next(iter(self.valid_loader))\n",
    "\n",
    "        # Sample training dataset\n",
    "        X_f, y_f = next(iter(self.train_loader))\n",
    "\n",
    "        theta_tp1 = self.network.state_dict()\n",
    "        for epoch in range(self.hyperparameters['n_epochs']):\n",
    "            # for epoch in range(2):\n",
    "            self.network = LeNet(n_out=10)\n",
    "            self.network.load_state_dict(theta_tp1)\n",
    "\n",
    "            self.network.train()\n",
    "\n",
    "            # Equation (1)\n",
    "            make_dot(weight_vec).render(\"weight_vec\", format=\"png\")\n",
    "            y_f_hat = self.network(X_f)\n",
    "            Costs = self.criterion(y_f_hat, y_f)\n",
    "            l_f_hat = torch.sum(torch.mul(Costs, weight_vec))\n",
    "\n",
    "            grad_t = torch.autograd.grad(outputs=l_f_hat, inputs=self.network.params(), create_graph=True)\n",
    "\n",
    "            lr = self.hyperparameters['learning_rate']\n",
    "            self.network.our_update_params_with_step(lr, grad_t)\n",
    "\n",
    "            # Equation (2)\n",
    "            y_g_hat = self.network(X_g)\n",
    "            l_g_hat = self.criterion_mean(y_g_hat, y_g)\n",
    "\n",
    "            grad_w = torch.autograd.grad(outputs=l_g_hat, inputs=weight_vec, create_graph=True)\n",
    "            lr = self.hyperparameters['learning_rate']\n",
    "            weight_vec = weight_vec - lr * grad_w[0]\n",
    "            weight_vec = torch.clamp(weight_vec, min=0)\n",
    "            print(max(weight_vec.data).item() - min(weight_vec.data).item())\n",
    "            \n",
    "            # Recreate network\n",
    "            theta_tp1 = self.network.state_dict()\n",
    "\n",
    "            # Validation testing\n",
    "            # if (epoch % self.hyperparameters['log_interval'] == 0):\n",
    "            self.network.eval()\n",
    "\n",
    "            acc = []\n",
    "            for itr,(test_img, test_label) in enumerate(self.test_loader):\n",
    "                prediction = self.network(test_img).detach().numpy()\n",
    "                prediction = np.argmax(prediction, axis=1)\n",
    "                # print(prediction)\n",
    "                # print(test_label.detach().numpy())\n",
    "                tmp = (prediction == test_label.detach().numpy())\n",
    "                tmp = tmp*1\n",
    "                acc.append(tmp)\n",
    "\n",
    "            accuracy = np.concatenate(acc).mean()\n",
    "            print(np.round(accuracy*100,2))\n",
    "            # acc_arr = np.array([epoch, accuracy.cpu().numpy()])\n",
    "            # accuracy_log.append(acc_arr[None])\n",
    "\n",
    "            ####################################################\n",
    "            weight_vec = weight_vec.detach()\n",
    "            weight_vec = weight_vec.requires_grad_()\n",
    "            ####################################################\n",
    "\n",
    "\n",
    "        \n",
    "    # Inside loop performs one epoch\n",
    "\n",
    "class Reweighting():\n",
    "    def __init__(self, network, hyperparameters, criterion, criterion_mean, optimizer, train_loader, valid_loader, test_loader):\n",
    "        self.network = network.requires_grad_(requires_grad=True)\n",
    "        self.hyperparameters = hyperparameters\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.valid_loader = valid_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.criterion_mean = criterion_mean\n",
    "\n",
    "    def train(self):\n",
    "        # X_g = LeNet5()\n",
    "        # print(\"Starting training...\")\n",
    "        X_g, y_g = next(iter(self.valid_loader))\n",
    "        # X_g = X_g.requires_grad_(requires_grad=True)\n",
    "        # Train the network\n",
    "        y_f_hat = torch.empty(1)\n",
    "\n",
    "        theta_tp1 = self.network.state_dict()\n",
    "        for epoch in range(self.hyperparameters['n_epochs']):\n",
    "            # print(\"Epoch loop\")\n",
    "            self.network.train()\n",
    "\n",
    "            self.meta_network = LeNet(n_out=10)\n",
    "            self.meta_network.load_state_dict(theta_tp1)\n",
    "            \n",
    "            # for param in theta_tp1:\n",
    "            #     param.grad = None\n",
    "            # self.network.our_update_params(theta_tp1)\n",
    "\n",
    "            # self.network.detach_params()\n",
    "            # self.network.our_update_params(self.network.params())\n",
    "            # self.network.copy(self.network, same_var=False)\n",
    "\n",
    "            # self.network.zero_grad()        #zero out any previously accumulated gradient before doing autograd\n",
    "\n",
    "            \n",
    "            # get batch of data from train_loader\n",
    "            X_f, y_f = next(iter(self.train_loader))\n",
    "            # print(\"X_f\", X_f.size())\n",
    "\n",
    "            # TODO: get batch of data from validation_loader (it is currently fixed outside the loop)\n",
    "\n",
    "            # Line 4\n",
    "            # make_dot(y_f_hat).render(\"y_f_hat\", format=\"png\")\n",
    "            y_f_hat = self.meta_network(X_f)\n",
    "            \n",
    "\n",
    "            # Line 5\n",
    "            epsilon = torch.zeros(y_f.size(), requires_grad=True)\n",
    "            Costs = self.criterion(y_f_hat, y_f)\n",
    "            l_f = torch.sum(torch.mul(Costs, epsilon))\n",
    "            # l_f = torch.sum(Costs * epsilon)\n",
    "            # make_dot(l_f).render(\"l_f\", format=\"png\")\n",
    "            \n",
    "\n",
    "            # Line 6\n",
    "            grad_t = torch.autograd.grad(outputs=l_f, inputs=self.meta_network.params(), create_graph=True)\n",
    "            # grad_t = torch.autograd.grad(l_f, self.network.parameters(), only_inputs=True)\n",
    "            # make_dot(grad_t).render(\"grad_t\", format=\"png\")\n",
    "            \n",
    "\n",
    "            # Line 7: manually update the weights of the validation network\n",
    "            # theta_t = self.meta_network.params()\n",
    "\n",
    "            lr = self.hyperparameters['learning_rate']\n",
    "            self.meta_network.our_update_params_with_step(lr, grad_t)\n",
    "\n",
    "            # Line 8\n",
    "            # Model has theta_hat\n",
    "            y_g_hat = self.meta_network(X_g)\n",
    "\n",
    "            # Line 9\n",
    "            l_g = self.criterion_mean(y_g_hat, y_g)\n",
    "            # make_dot(l_g).render(\"want_big_graph\", format=\"png\")\n",
    "            # print(y_g_hat)\n",
    "\n",
    "            # Line 10\n",
    "            grad_epsilon = torch.autograd.grad(l_g, epsilon, only_inputs=True)[0]\n",
    "            # make_dot(grad_epsilon).render(\"grad_epsilon\", format=\"png\")\n",
    "\n",
    "            # Line 11\n",
    "            w_tilde = torch.clamp(-grad_epsilon, min=0)\n",
    "\n",
    "            if torch.sum(w_tilde) != 0:\n",
    "                w = w_tilde / torch.sum(w_tilde)\n",
    "            else:\n",
    "                w = w_tilde\n",
    "\n",
    "            # Line 12\n",
    "            y_f_hat = self.network(X_f)\n",
    "            Costs = self.criterion(y_f_hat, y_f)\n",
    "            l_f_hat = torch.sum(torch.mul(Costs, w))\n",
    "            # print(\"l_f_hat\", l_f_hat.item())\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Line 13\n",
    "            l_f_hat.backward()\n",
    "\n",
    "            # Line 14\n",
    "            self.optimizer.step()\n",
    "            # break\n",
    "\n",
    "            theta_tp1 = self.network.state_dict()\n",
    "\n",
    "            if (epoch % self.hyperparameters['log_interval'] == 0):\n",
    "                self.network.eval()\n",
    "\n",
    "                acc = []\n",
    "                for itr,(test_img, test_label) in enumerate(self.test_loader):\n",
    "                    prediction = self.network(test_img).detach().numpy()\n",
    "                    prediction = np.argmax(prediction, axis=1)\n",
    "                    # print(prediction)\n",
    "                    # print(test_label.detach().numpy())\n",
    "                    tmp = (prediction == test_label.detach().numpy())\n",
    "                    tmp = tmp*1\n",
    "                    acc.append(tmp)\n",
    "\n",
    "                accuracy = np.concatenate(acc).mean()\n",
    "                print(np.round(accuracy*100,2))\n",
    "                # acc_arr = np.array([epoch, accuracy.cpu().numpy()])\n",
    "                # accuracy_log.append(acc_arr[None])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020999999716877937"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_vec = torch.ones(len(train_loader.dataset)) * 1.0/len(train_loader.dataset)\n",
    "weight_vec.requires_grad_()\n",
    "weight_vec\n",
    "\n",
    "loss = torch.sum(torch.mul(2.0, weight_vec))\n",
    "\n",
    "grad_w = torch.autograd.grad(outputs=loss, inputs=weight_vec, create_graph=True)\n",
    "weight_vec = weight_vec + 0.01 * grad_w[0]\n",
    "\n",
    "weight_vec.detach()\n",
    "weight_vec.requires_grad_()\n",
    "\n",
    "max(weight_vec.data).item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8084345103707165e-05\n",
      "12.69\n",
      "5.629741644952446e-05\n",
      "12.81\n",
      "8.425907435594127e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 72\u001b[0m\n\u001b[0;32m     69\u001b[0m valid_loader \u001b[38;5;241m=\u001b[39m data_loader\u001b[38;5;241m.\u001b[39mvalid_dataloader\n\u001b[0;32m     70\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m data_loader\u001b[38;5;241m.\u001b[39mtest_dataloader\n\u001b[1;32m---> 72\u001b[0m NaiveReweighting(network, hyperparameters, criterion, criterion_mean, optimizer, train_loader, valid_loader, test_loader)\u001b[38;5;241m.\u001b[39mtrain()\n",
      "Cell \u001b[1;32mIn[2], line 152\u001b[0m, in \u001b[0;36mNaiveReweighting.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m    151\u001b[0m acc \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 152\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m itr,(test_img, test_label) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_loader):\n\u001b[0;32m    153\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork(test_img)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    154\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(prediction, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jjuus\\anaconda3\\envs\\ECE50024\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\jjuus\\anaconda3\\envs\\ECE50024\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\jjuus\\anaconda3\\envs\\ECE50024\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\jjuus\\anaconda3\\envs\\ECE50024\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\jjuus\\anaconda3\\envs\\ECE50024\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(img)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\Users\\jjuus\\anaconda3\\envs\\ECE50024\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\jjuus\\anaconda3\\envs\\ECE50024\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jjuus\\anaconda3\\envs\\ECE50024\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jjuus\\anaconda3\\envs\\ECE50024\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mnormalize(tensor, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstd, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minplace)\n",
      "File \u001b[1;32mc:\\Users\\jjuus\\anaconda3\\envs\\ECE50024\\Lib\\site-packages\\torchvision\\transforms\\functional.py:349\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39mnormalize(tensor, mean\u001b[38;5;241m=\u001b[39mmean, std\u001b[38;5;241m=\u001b[39mstd, inplace\u001b[38;5;241m=\u001b[39minplace)\n",
      "File \u001b[1;32mc:\\Users\\jjuus\\anaconda3\\envs\\ECE50024\\Lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:915\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    910\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected tensor to be a tensor image of size (..., C, H, W). Got tensor.size() = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    912\u001b[0m     )\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inplace:\n\u001b[1;32m--> 915\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m    917\u001b[0m dtype \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    918\u001b[0m mean \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(mean, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# from torchviz import make_dot\n",
    "\n",
    "from model import LeNet5\n",
    "from meta_model import MetaModule, LeNet\n",
    "from dataloader import MNISTDataLoader\n",
    "\n",
    "\n",
    "network = LeNet(n_out=10)\n",
    "\n",
    "hyperparameters = {\n",
    "    'n_epochs' : 1000,\n",
    "    'batch_size_train' : 100,\n",
    "    'batch_size_valid' : 3000,\n",
    "    'batch_size_test' : 1000,\n",
    "    'learning_rate' : 1e-2,\n",
    "    'momentum' : 0.5,\n",
    "    'log_interval' : 100\n",
    "}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "# criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
    "criterion_mean = nn.CrossEntropyLoss(reduction='mean')\n",
    "# criterion_mean = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "\n",
    "optimizer = optim.SGD(network.params(),\n",
    "                        lr=hyperparameters['learning_rate'],\n",
    "                        momentum=hyperparameters['momentum'])\n",
    "# Load the data\n",
    "data_loader = MNISTDataLoader(validation_ratio=0.05,\n",
    "                              batch_size_train=hyperparameters['batch_size_train'],\n",
    "                              batch_size_valid=hyperparameters['batch_size_valid'],\n",
    "                              batch_size_test=hyperparameters['batch_size_test'])\n",
    "\n",
    "# Add sample bias and corruption to the data\n",
    "desired_sample_distribution = [100, 100, 100, 100, 100, 100, 100, 100, 100, 20]\n",
    "data_loader.sample_bias(desired_sample_distribution, dataset=\"train\")\n",
    "# data_loader.plot_dist(dataset=\"train\")\n",
    "# data_loader.plot_dist(dataset=\"valid\")\n",
    "# data_loader.plot_dist(dataset=\"test\")\n",
    "# print(data_loader.get_num(\"train\"))\n",
    "\n",
    "train_loader = data_loader.train_dataloader\n",
    "valid_loader = data_loader.valid_dataloader\n",
    "test_loader = data_loader.test_dataloader\n",
    "\n",
    "# NoReweighting(network, hyperparameters, criterion, optimizer, train_loader, test_loader).train()\n",
    "# NaiveReweighting(network, hyperparameters, criterion, optimizer, train_loader, test_loader).train()\n",
    "# Reweighting(network, hyperparameters, criterion, criterion_mean, optimizer, train_loader, valid_loader, test_loader).train()\n",
    "\n",
    "\n",
    "# Load the data\n",
    "data_loader = MNISTDataLoader(validation_ratio=0.05,\n",
    "                              batch_size_train=60000,\n",
    "                              batch_size_valid=hyperparameters['batch_size_valid'],\n",
    "                              batch_size_test=hyperparameters['batch_size_test'],\n",
    "                              shuffle=False)\n",
    "\n",
    "desired_sample_distribution = [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]\n",
    "data_loader.sample_bias(desired_sample_distribution, dataset=\"train\", dist_is_freq=False)\n",
    "\n",
    "train_loader = data_loader.train_dataloader\n",
    "valid_loader = data_loader.valid_dataloader\n",
    "test_loader = data_loader.test_dataloader\n",
    "\n",
    "NaiveReweighting(network, hyperparameters, criterion, criterion_mean, optimizer, train_loader, valid_loader, test_loader).train()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hyperparameters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m MNISTDataLoader(validation_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m,\n\u001b[0;32m      3\u001b[0m                               batch_size_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6000\u001b[39m,\n\u001b[1;32m----> 4\u001b[0m                               batch_size_valid\u001b[38;5;241m=\u001b[39mhyperparameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size_valid\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      5\u001b[0m                               batch_size_test\u001b[38;5;241m=\u001b[39mhyperparameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size_test\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      6\u001b[0m                               shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Add sample bias and corruption to the data\u001b[39;00m\n\u001b[0;32m      9\u001b[0m desired_sample_distribution \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hyperparameters' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data_loader = MNISTDataLoader(validation_ratio=0.05,\n",
    "                              batch_size_train=6000,\n",
    "                              batch_size_valid=hyperparameters['batch_size_valid'],\n",
    "                              batch_size_test=hyperparameters['batch_size_test'],\n",
    "                              shuffle=False)\n",
    "\n",
    "# Add sample bias and corruption to the data\n",
    "desired_sample_distribution = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "data_loader.sample_bias(desired_sample_distribution, dataset=\"train\", dist_is_freq=False)\n",
    "\n",
    "data_loader.plot_dist(\"train\")\n",
    "# data_loader.train_dataloader.shuffle\n",
    "\n",
    "for lcv in range(5):\n",
    "    X_f, y_f = next(iter(data_loader.train_dataloader))\n",
    "    print(y_f)\n",
    "\n",
    "for lcv in range(5):\n",
    "    X_f, y_f = next(iter(data_loader.train_dataloader))\n",
    "    print(y_f)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECE50024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
